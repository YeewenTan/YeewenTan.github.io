<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">
<!-- NewPage -->
<html lang="en">
<head>
<!-- Generated by javadoc (version 1.7.0_21) on Sat Apr 05 12:45:40 PDT 2014 -->
<title>BaseMultiLayerNetwork</title>
<meta name="date" content="2014-04-05">
<link rel="stylesheet" type="text/css" href="../../../stylesheet.css" title="Style">
</head>
<body>
<script type="text/javascript"><!--
    if (location.href.indexOf('is-external=true') == -1) {
        parent.document.title="BaseMultiLayerNetwork";
    }
//-->
</script>
<noscript>
<div>JavaScript is disabled on your browser.</div>
</noscript>
<!-- ========= START OF TOP NAVBAR ======= -->
<div class="topNav"><a name="navbar_top">
<!--   -->
</a><a href="#skip-navbar_top" title="Skip navigation links"></a><a name="navbar_top_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.Builder.html" title="class in org.deeplearning4j.nn"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/deeplearning4j/nn/BaseMultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="BaseMultiLayerNetwork.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_top">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_top");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_top">
<!--   -->
</a></div>
<!-- ========= END OF TOP NAVBAR ========= -->
<!-- ======== START OF CLASS DATA ======== -->
<div class="header">
<div class="subTitle">org.deeplearning4j.nn</div>
<h2 title="Class BaseMultiLayerNetwork" class="title">Class BaseMultiLayerNetwork</h2>
</div>
<div class="contentContainer">
<ul class="inheritance">
<li>java.lang.Object</li>
<li>
<ul class="inheritance">
<li>org.deeplearning4j.nn.BaseMultiLayerNetwork</li>
</ul>
</li>
</ul>
<div class="description">
<ul class="blockList">
<li class="blockList">
<dl>
<dt>All Implemented Interfaces:</dt>
<dd>java.io.Serializable, <a href="../../../org/deeplearning4j/nn/Persistable.html" title="interface in org.deeplearning4j.nn">Persistable</a></dd>
</dl>
<dl>
<dt>Direct Known Subclasses:</dt>
<dd><a href="../../../org/deeplearning4j/dbn/DBN.html" title="class in org.deeplearning4j.dbn">DBN</a>, <a href="../../../org/deeplearning4j/sda/StackedDenoisingAutoEncoder.html" title="class in org.deeplearning4j.sda">StackedDenoisingAutoEncoder</a></dd>
</dl>
<hr>
<br>
<pre>public abstract class <span class="strong">BaseMultiLayerNetwork</span>
extends java.lang.Object
implements java.io.Serializable, <a href="../../../org/deeplearning4j/nn/Persistable.html" title="interface in org.deeplearning4j.nn">Persistable</a></pre>
<div class="block">A base class for a multi layer neural network with a logistic output layer
 and multiple hidden layers.</div>
<dl><dt><span class="strong">See Also:</span></dt><dd><a href="../../../serialized-form.html#org.deeplearning4j.nn.BaseMultiLayerNetwork">Serialized Form</a></dd></dl>
</li>
</ul>
</div>
<div class="summary">
<ul class="blockList">
<li class="blockList">
<!-- ======== NESTED CLASS SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="nested_class_summary">
<!--   -->
</a>
<h3>Nested Class Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Nested Class Summary table, listing nested classes, and an explanation">
<caption><span>Nested Classes</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Class and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static class&nbsp;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.Builder.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork.Builder</a>&lt;<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.Builder.html" title="type parameter in BaseMultiLayerNetwork.Builder">E</a> extends <a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&gt;</strong></code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- =========== FIELD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_summary">
<!--   -->
</a>
<h3>Field Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Field Summary table, listing fields, and an explanation">
<caption><span>Fields</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Field and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#dropOut">dropOut</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#errorTolerance">errorTolerance</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected java.util.Map&lt;java.lang.Integer,java.util.List&lt;<a href="../../../org/deeplearning4j/gradient/NeuralNetworkGradientListener.html" title="interface in org.deeplearning4j.gradient">NeuralNetworkGradientListener</a>&gt;&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#gradientListeners">gradientListeners</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#learningRateUpdate">learningRateUpdate</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected <a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#lossFunction">lossFunction</a></strong></code>
<div class="block">Which loss function to use:
 Squared loss, Reconstruction entropy, negative log likelihood</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected java.util.List&lt;<a href="../../../org/deeplearning4j/gradient/multilayer/MultiLayerGradientListener.html" title="interface in org.deeplearning4j.gradient.multilayer">MultiLayerGradientListener</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#multiLayerGradientListeners">multiLayerGradientListeners</a></strong></code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#normalizeByInputRows">normalizeByInputRows</a></strong></code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected <a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#optimizationAlgorithm">optimizationAlgorithm</a></strong></code>
<div class="block">Which optimization algorithm to use: SGD or CG</div>
</td>
</tr>
</table>
</li>
</ul>
<!-- ======== CONSTRUCTOR SUMMARY ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_summary">
<!--   -->
</a>
<h3>Constructor Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Constructor Summary table, listing constructors, and an explanation">
<caption><span>Constructors</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier</th>
<th class="colLast" scope="col">Constructor and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected </code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#BaseMultiLayerNetwork()">BaseMultiLayerNetwork</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected </code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#BaseMultiLayerNetwork(int, int[], int, int, org.apache.commons.math3.random.RandomGenerator)">BaseMultiLayerNetwork</a></strong>(int&nbsp;nIns,
                     int[]&nbsp;hiddenLayerSizes,
                     int&nbsp;nOuts,
                     int&nbsp;nLayers,
                     org.apache.commons.math3.random.RandomGenerator&nbsp;rng)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected </code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#BaseMultiLayerNetwork(int, int[], int, int, org.apache.commons.math3.random.RandomGenerator, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix)">BaseMultiLayerNetwork</a></strong>(int&nbsp;nIn,
                     int[]&nbsp;hiddenLayerSizes,
                     int&nbsp;nOuts,
                     int&nbsp;nLayers,
                     org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
                     org.jblas.DoubleMatrix&nbsp;input,
                     org.jblas.DoubleMatrix&nbsp;labels)</code>&nbsp;</td>
</tr>
</table>
</li>
</ul>
<!-- ========== METHOD SUMMARY =========== -->
<ul class="blockList">
<li class="blockList"><a name="method_summary">
<!--   -->
</a>
<h3>Method Summary</h3>
<table class="overviewSummary" border="0" cellpadding="3" cellspacing="0" summary="Method Summary table, listing methods, and an explanation">
<caption><span>Methods</span><span class="tabEnd">&nbsp;</span></caption>
<tr>
<th class="colFirst" scope="col">Modifier and Type</th>
<th class="colLast" scope="col">Method and Description</th>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#applyTransforms()">applyTransforms</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#asDecoder(org.deeplearning4j.nn.BaseMultiLayerNetwork)">asDecoder</a></strong>(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</code>
<div class="block">Set as decoder for another neural net
 designed for encoding (primary output is
 encoding input)</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#backProp(double, int)">backProp</a></strong>(double&nbsp;lr,
        int&nbsp;epochs)</code>
<div class="block">Backpropagation of errors for weights</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#backPropStep(org.deeplearning4j.nn.BaseMultiLayerNetwork, double, int)">backPropStep</a></strong>(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;revert,
            double&nbsp;lr,
            int&nbsp;epoch)</code>
<div class="block">Do a back prop iteration.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#clone()">clone</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#createHiddenLayer(int, int, int, org.deeplearning4j.nn.activation.ActivationFunction, org.apache.commons.math3.random.RandomGenerator, org.jblas.DoubleMatrix, org.apache.commons.math3.distribution.RealDistribution)">createHiddenLayer</a></strong>(int&nbsp;index,
                 int&nbsp;nIn,
                 int&nbsp;nOut,
                 <a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a>&nbsp;activation,
                 org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
                 org.jblas.DoubleMatrix&nbsp;layerInput,
                 org.apache.commons.math3.distribution.RealDistribution&nbsp;dist)</code>
<div class="block">Creates a hidden layer with the given parameters.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>abstract <a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#createLayer(org.jblas.DoubleMatrix, int, int, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, org.apache.commons.math3.random.RandomGenerator, int)">createLayer</a></strong>(org.jblas.DoubleMatrix&nbsp;input,
           int&nbsp;nVisible,
           int&nbsp;nHidden,
           org.jblas.DoubleMatrix&nbsp;W,
           org.jblas.DoubleMatrix&nbsp;hbias,
           org.jblas.DoubleMatrix&nbsp;vBias,
           org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
           int&nbsp;index)</code>
<div class="block">Creates a layer depending on the index.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>abstract <a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#createNetworkLayers(int)">createNetworkLayers</a></strong>(int&nbsp;numLayers)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#encode(org.deeplearning4j.nn.BaseMultiLayerNetwork)">encode</a></strong>(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</code>
<div class="block">Transposes this network to turn it in to
 ad encoder for the given auto encoder networkk</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#fanIn()">fanIn</a></strong>()</code>
<div class="block">Returns the -fanIn to fanIn
 coefficient used for initializing the
 weights.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.List&lt;org.jblas.DoubleMatrix&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#feedForward()">feedForward</a></strong>()</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.List&lt;org.jblas.DoubleMatrix&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#feedForward(org.jblas.DoubleMatrix)">feedForward</a></strong>(org.jblas.DoubleMatrix&nbsp;input)</code>
<div class="block">Compute activations from input to output of the output layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#finetune(double, int)">finetune</a></strong>(double&nbsp;lr,
        int&nbsp;epochs)</code>
<div class="block">Finetunes with the current cached labels</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#finetune(org.jblas.DoubleMatrix, double, int)">finetune</a></strong>(org.jblas.DoubleMatrix&nbsp;labels,
        double&nbsp;lr,
        int&nbsp;epochs)</code>
<div class="block">Run SGD based on the given labels</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getActivation()">getActivation</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getColumnMeans()">getColumnMeans</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getColumnStds()">getColumnStds</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getColumnSums()">getColumnSums</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.commons.math3.distribution.RealDistribution</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getDist()">getDist</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getDropOut()">getDropOut</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getErrorTolerance()">getErrorTolerance</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getFanIn()">getFanIn</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/gradient/MultiLayerGradient.html" title="class in org.deeplearning4j.nn.gradient">MultiLayerGradient</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getGradient(java.lang.Object[])">getGradient</a></strong>(java.lang.Object[]&nbsp;params)</code>
<div class="block">Gets the multi layer gradient for this network.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getHiddenBiasTransforms()">getHiddenBiasTransforms</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int[]</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getHiddenLayerSizes()">getHiddenLayerSizes</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getInput()">getInput</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getL2()">getL2</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getLabels()">getLabels</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getLayers()">getLayers</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getLearningRateUpdate()">getLearningRateUpdate</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/LogisticRegression.html" title="class in org.deeplearning4j.nn">LogisticRegression</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getLogLayer()">getLogLayer</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getLossFunction()">getLossFunction</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getMomentum()">getMomentum</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getnIns()">getnIns</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getnLayers()">getnLayers</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getnOuts()">getnOuts</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getOptimizationAlgorithm()">getOptimizationAlgorithm</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/optimize/MultiLayerNetworkOptimizer.html" title="class in org.deeplearning4j.optimize">MultiLayerNetworkOptimizer</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getOptimizer()">getOptimizer</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getReconstructionCrossEntropy()">getReconstructionCrossEntropy</a></strong>()</code>
<div class="block">Returns the sum of the reconstruction entropies
 divided by the number of layers</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>int</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getRenderWeightsEveryNEpochs()">getRenderWeightsEveryNEpochs</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.apache.commons.math3.random.RandomGenerator</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getRng()">getRng</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code><a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a>[]</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getSigmoidLayers()">getSigmoidLayers</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getSparsity()">getSparsity</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getVisibleBiasTransforms()">getVisibleBiasTransforms</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#getWeightTransforms()">getWeightTransforms</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#init()">init</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#initialize(org.deeplearning4j.datasets.DataSet)">initialize</a></strong>(<a href="../../../org/deeplearning4j/datasets/DataSet.html" title="class in org.deeplearning4j.datasets">DataSet</a>&nbsp;data)</code>
<div class="block">Sets the input and labels from this dataset</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#initializeLayers(org.jblas.DoubleMatrix)">initializeLayers</a></strong>(org.jblas.DoubleMatrix&nbsp;input)</code>
<div class="block">Base class for initializing the layers based on the input.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#initializeNetwork(org.deeplearning4j.nn.NeuralNetwork)">initializeNetwork</a></strong>(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>&nbsp;network)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isForceNumEpochs()">isForceNumEpochs</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isNormalizeByInputRows()">isNormalizeByInputRows</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isShouldBackProp()">isShouldBackProp</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isShouldInit()">isShouldInit</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isToDecode()">isToDecode</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isUseAdaGrad()">isUseAdaGrad</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isUseHiddenActivationsForwardProp()">isUseHiddenActivationsForwardProp</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>boolean</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#isUseRegularization()">isUseRegularization</a></strong>()</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#load(java.io.InputStream)">load</a></strong>(java.io.InputStream&nbsp;is)</code>
<div class="block">Load (using <code>ObjectInputStream</code></div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>static <a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a></code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#loadFromFile(java.io.InputStream)">loadFromFile</a></strong>(java.io.InputStream&nbsp;is)</code>
<div class="block">Load (using <code>ObjectInputStream</code></div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#merge(org.deeplearning4j.nn.BaseMultiLayerNetwork, int)">merge</a></strong>(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network,
     int&nbsp;batchSize)</code>
<div class="block">Merges this network with the other one.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>double</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#negativeLogLikelihood()">negativeLogLikelihood</a></strong>()</code>
<div class="block">Negative log likelihood of the model</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#predict(org.jblas.DoubleMatrix)">predict</a></strong>(org.jblas.DoubleMatrix&nbsp;x)</code>
<div class="block">Label the probabilities of the input</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#pretrain(org.jblas.DoubleMatrix, java.lang.Object[])">pretrain</a></strong>(org.jblas.DoubleMatrix&nbsp;input,
        java.lang.Object[]&nbsp;otherParams)</code>
<div class="block">Pretrain the network with the given parameters</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#reconstruct(org.jblas.DoubleMatrix)">reconstruct</a></strong>(org.jblas.DoubleMatrix&nbsp;x)</code>
<div class="block">Reconstruct from the final layer</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>org.jblas.DoubleMatrix</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#reconstruct(org.jblas.DoubleMatrix, int)">reconstruct</a></strong>(org.jblas.DoubleMatrix&nbsp;x,
           int&nbsp;layerNum)</code>
<div class="block">Reconstructs the input.</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#resetAdaGrad(double)">resetAdaGrad</a></strong>(double&nbsp;lr)</code>
<div class="block">Resets adagrad with the given learning rate.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setActivation(org.deeplearning4j.nn.activation.ActivationFunction)">setActivation</a></strong>(<a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a>&nbsp;activation)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setColumnMeans(org.jblas.DoubleMatrix)">setColumnMeans</a></strong>(org.jblas.DoubleMatrix&nbsp;columnMeans)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setColumnStds(org.jblas.DoubleMatrix)">setColumnStds</a></strong>(org.jblas.DoubleMatrix&nbsp;columnStds)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setColumnSums(org.jblas.DoubleMatrix)">setColumnSums</a></strong>(org.jblas.DoubleMatrix&nbsp;columnSums)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setDist(org.apache.commons.math3.distribution.RealDistribution)">setDist</a></strong>(org.apache.commons.math3.distribution.RealDistribution&nbsp;dist)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setDropOut(double)">setDropOut</a></strong>(double&nbsp;dropOut)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setErrorTolerance(double)">setErrorTolerance</a></strong>(double&nbsp;errorTolerance)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setFanIn(double)">setFanIn</a></strong>(double&nbsp;fanIn)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setForceNumEpochs(boolean)">setForceNumEpochs</a></strong>(boolean&nbsp;forceNumEpochs)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setHiddenLayerSizes(int[])">setHiddenLayerSizes</a></strong>(int[]&nbsp;hiddenLayerSizes)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setInput(org.jblas.DoubleMatrix)">setInput</a></strong>(org.jblas.DoubleMatrix&nbsp;input)</code>
<div class="block">Note that if input isn't null
 and the layers are null, this is a way
 of initializing the neural network</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setL2(double)">setL2</a></strong>(double&nbsp;l2)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setLabels(org.jblas.DoubleMatrix)">setLabels</a></strong>(org.jblas.DoubleMatrix&nbsp;labels)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setLayers(org.deeplearning4j.nn.NeuralNetwork[])">setLayers</a></strong>(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]&nbsp;layers)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setLearningRateUpdate(double)">setLearningRateUpdate</a></strong>(double&nbsp;learningRateUpdate)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setLogLayer(org.deeplearning4j.nn.LogisticRegression)">setLogLayer</a></strong>(<a href="../../../org/deeplearning4j/nn/LogisticRegression.html" title="class in org.deeplearning4j.nn">LogisticRegression</a>&nbsp;logLayer)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setLossFunction(org.deeplearning4j.nn.NeuralNetwork.LossFunction)">setLossFunction</a></strong>(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a>&nbsp;lossFunction)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setMomentum(double)">setMomentum</a></strong>(double&nbsp;momentum)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setnIns(int)">setnIns</a></strong>(int&nbsp;nIns)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setnLayers(int)">setnLayers</a></strong>(int&nbsp;nLayers)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setNormalizeByInputRows(boolean)">setNormalizeByInputRows</a></strong>(boolean&nbsp;normalizeByInputRows)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setnOuts(int)">setnOuts</a></strong>(int&nbsp;nOuts)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setOptimizationAlgorithm(org.deeplearning4j.nn.NeuralNetwork.OptimizationAlgorithm)">setOptimizationAlgorithm</a></strong>(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a>&nbsp;optimizationAlgorithm)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setOptimizer(org.deeplearning4j.optimize.MultiLayerNetworkOptimizer)">setOptimizer</a></strong>(<a href="../../../org/deeplearning4j/optimize/MultiLayerNetworkOptimizer.html" title="class in org.deeplearning4j.optimize">MultiLayerNetworkOptimizer</a>&nbsp;optimizer)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setRenderWeightsEveryNEpochs(int)">setRenderWeightsEveryNEpochs</a></strong>(int&nbsp;renderWeightsEveryNEpochs)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setRng(org.apache.commons.math3.random.RandomGenerator)">setRng</a></strong>(org.apache.commons.math3.random.RandomGenerator&nbsp;rng)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setShouldBackProp(boolean)">setShouldBackProp</a></strong>(boolean&nbsp;shouldBackProp)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setShouldInit(boolean)">setShouldInit</a></strong>(boolean&nbsp;shouldInit)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setSigmoidLayers(org.deeplearning4j.nn.HiddenLayer[])">setSigmoidLayers</a></strong>(<a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a>[]&nbsp;sigmoidLayers)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setSparsity(double)">setSparsity</a></strong>(double&nbsp;sparsity)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setToDecode(boolean)">setToDecode</a></strong>(boolean&nbsp;toDecode)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setUseAdaGrad(boolean)">setUseAdaGrad</a></strong>(boolean&nbsp;useAdaGrad)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setUseHiddenActivationsForwardProp(boolean)">setUseHiddenActivationsForwardProp</a></strong>(boolean&nbsp;useHiddenActivationsForwardProp)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setUseRegularization(boolean)">setUseRegularization</a></strong>(boolean&nbsp;useRegularization)</code>&nbsp;</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#setWeightTransforms(java.util.Map)">setWeightTransforms</a></strong>(java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;&nbsp;weightTransforms)</code>&nbsp;</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#synchonrizeRng()">synchonrizeRng</a></strong>()</code>
<div class="block">Synchronizes the rng, this is mean for use with scale out methods</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>abstract void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#trainNetwork(org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, java.lang.Object[])">trainNetwork</a></strong>(org.jblas.DoubleMatrix&nbsp;input,
            org.jblas.DoubleMatrix&nbsp;labels,
            java.lang.Object[]&nbsp;otherParams)</code>
<div class="block">Train the network running some unsupervised
 pretraining followed by SGD/finetune</div>
</td>
</tr>
<tr class="rowColor">
<td class="colFirst"><code>protected void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#update(org.deeplearning4j.nn.BaseMultiLayerNetwork)">update</a></strong>(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</code>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network.</div>
</td>
</tr>
<tr class="altColor">
<td class="colFirst"><code>void</code></td>
<td class="colLast"><code><strong><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html#write(java.io.OutputStream)">write</a></strong>(java.io.OutputStream&nbsp;os)</code>&nbsp;</td>
</tr>
</table>
<ul class="blockList">
<li class="blockList"><a name="methods_inherited_from_class_java.lang.Object">
<!--   -->
</a>
<h3>Methods inherited from class&nbsp;java.lang.Object</h3>
<code>equals, finalize, getClass, hashCode, notify, notifyAll, toString, wait, wait, wait</code></li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="details">
<ul class="blockList">
<li class="blockList">
<!-- ============ FIELD DETAIL =========== -->
<ul class="blockList">
<li class="blockList"><a name="field_detail">
<!--   -->
</a>
<h3>Field Detail</h3>
<a name="learningRateUpdate">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>learningRateUpdate</h4>
<pre>public&nbsp;double learningRateUpdate</pre>
</li>
</ul>
<a name="errorTolerance">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>errorTolerance</h4>
<pre>public&nbsp;double errorTolerance</pre>
</li>
</ul>
<a name="gradientListeners">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>gradientListeners</h4>
<pre>protected&nbsp;java.util.Map&lt;java.lang.Integer,java.util.List&lt;<a href="../../../org/deeplearning4j/gradient/NeuralNetworkGradientListener.html" title="interface in org.deeplearning4j.gradient">NeuralNetworkGradientListener</a>&gt;&gt; gradientListeners</pre>
</li>
</ul>
<a name="multiLayerGradientListeners">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>multiLayerGradientListeners</h4>
<pre>protected&nbsp;java.util.List&lt;<a href="../../../org/deeplearning4j/gradient/multilayer/MultiLayerGradientListener.html" title="interface in org.deeplearning4j.gradient.multilayer">MultiLayerGradientListener</a>&gt; multiLayerGradientListeners</pre>
</li>
</ul>
<a name="dropOut">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>dropOut</h4>
<pre>protected&nbsp;double dropOut</pre>
</li>
</ul>
<a name="normalizeByInputRows">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>normalizeByInputRows</h4>
<pre>protected&nbsp;boolean normalizeByInputRows</pre>
</li>
</ul>
<a name="optimizationAlgorithm">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>optimizationAlgorithm</h4>
<pre>protected&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a> optimizationAlgorithm</pre>
<div class="block">Which optimization algorithm to use: SGD or CG</div>
</li>
</ul>
<a name="lossFunction">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>lossFunction</h4>
<pre>protected&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a> lossFunction</pre>
<div class="block">Which loss function to use:
 Squared loss, Reconstruction entropy, negative log likelihood</div>
</li>
</ul>
</li>
</ul>
<!-- ========= CONSTRUCTOR DETAIL ======== -->
<ul class="blockList">
<li class="blockList"><a name="constructor_detail">
<!--   -->
</a>
<h3>Constructor Detail</h3>
<a name="BaseMultiLayerNetwork()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>BaseMultiLayerNetwork</h4>
<pre>protected&nbsp;BaseMultiLayerNetwork()</pre>
</li>
</ul>
<a name="BaseMultiLayerNetwork(int, int[], int, int, org.apache.commons.math3.random.RandomGenerator)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>BaseMultiLayerNetwork</h4>
<pre>protected&nbsp;BaseMultiLayerNetwork(int&nbsp;nIns,
                     int[]&nbsp;hiddenLayerSizes,
                     int&nbsp;nOuts,
                     int&nbsp;nLayers,
                     org.apache.commons.math3.random.RandomGenerator&nbsp;rng)</pre>
</li>
</ul>
<a name="BaseMultiLayerNetwork(int, int[], int, int, org.apache.commons.math3.random.RandomGenerator, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>BaseMultiLayerNetwork</h4>
<pre>protected&nbsp;BaseMultiLayerNetwork(int&nbsp;nIn,
                     int[]&nbsp;hiddenLayerSizes,
                     int&nbsp;nOuts,
                     int&nbsp;nLayers,
                     org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
                     org.jblas.DoubleMatrix&nbsp;input,
                     org.jblas.DoubleMatrix&nbsp;labels)</pre>
</li>
</ul>
</li>
</ul>
<!-- ============ METHOD DETAIL ========== -->
<ul class="blockList">
<li class="blockList"><a name="method_detail">
<!--   -->
</a>
<h3>Method Detail</h3>
<a name="fanIn()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>fanIn</h4>
<pre>public&nbsp;double&nbsp;fanIn()</pre>
<div class="block">Returns the -fanIn to fanIn
 coefficient used for initializing the
 weights.
 The default is 1 / nIns</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the fan in coefficient</dd></dl>
</li>
</ul>
<a name="synchonrizeRng()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>synchonrizeRng</h4>
<pre>public&nbsp;void&nbsp;synchonrizeRng()</pre>
<div class="block">Synchronizes the rng, this is mean for use with scale out methods</div>
</li>
</ul>
<a name="resetAdaGrad(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>resetAdaGrad</h4>
<pre>public&nbsp;void&nbsp;resetAdaGrad(double&nbsp;lr)</pre>
<div class="block">Resets adagrad with the given learning rate.
 This is used for switching from the pretrain to finetune phase.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lr</code> - the new master learning rate to use</dd></dl>
</li>
</ul>
<a name="getReconstructionCrossEntropy()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getReconstructionCrossEntropy</h4>
<pre>public&nbsp;double&nbsp;getReconstructionCrossEntropy()</pre>
<div class="block">Returns the sum of the reconstruction entropies
 divided by the number of layers</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the average reconstruction entropy across layers</dd></dl>
</li>
</ul>
<a name="asDecoder(org.deeplearning4j.nn.BaseMultiLayerNetwork)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>asDecoder</h4>
<pre>public&nbsp;void&nbsp;asDecoder(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</pre>
<div class="block">Set as decoder for another neural net
 designed for encoding (primary output is
 encoding input)</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to decode</dd></dl>
</li>
</ul>
<a name="initializeLayers(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeLayers</h4>
<pre>public&nbsp;void&nbsp;initializeLayers(org.jblas.DoubleMatrix&nbsp;input)</pre>
<div class="block">Base class for initializing the layers based on the input.
 This is meant for capturing numbers such as input columns or other things.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input matrix for training</dd></dl>
</li>
</ul>
<a name="init()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>init</h4>
<pre>public&nbsp;void&nbsp;init()</pre>
</li>
</ul>
<a name="initializeNetwork(org.deeplearning4j.nn.NeuralNetwork)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initializeNetwork</h4>
<pre>protected&nbsp;void&nbsp;initializeNetwork(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>&nbsp;network)</pre>
</li>
</ul>
<a name="finetune(double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finetune</h4>
<pre>public&nbsp;void&nbsp;finetune(double&nbsp;lr,
            int&nbsp;epochs)</pre>
<div class="block">Finetunes with the current cached labels</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lr</code> - the learning rate to use</dd><dd><code>epochs</code> - the max number of epochs to finetune with</dd></dl>
</li>
</ul>
<a name="initialize(org.deeplearning4j.datasets.DataSet)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>initialize</h4>
<pre>public&nbsp;void&nbsp;initialize(<a href="../../../org/deeplearning4j/datasets/DataSet.html" title="class in org.deeplearning4j.datasets">DataSet</a>&nbsp;data)</pre>
<div class="block">Sets the input and labels from this dataset</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>data</code> - the dataset to initialize with</dd></dl>
</li>
</ul>
<a name="getGradient(java.lang.Object[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getGradient</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/gradient/MultiLayerGradient.html" title="class in org.deeplearning4j.nn.gradient">MultiLayerGradient</a>&nbsp;getGradient(java.lang.Object[]&nbsp;params)</pre>
<div class="block">Gets the multi layer gradient for this network.
 This includes calculating the gradients for each layer</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>params</code> - the params to pass (k, corruption level,...)</dd><dd><code>lr</code> - the learning rate to use for logistic regression</dd>
<dt><span class="strong">Returns:</span></dt><dd>the multi layer gradient for the whole network</dd></dl>
</li>
</ul>
<a name="feedForward()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.jblas.DoubleMatrix&gt;&nbsp;feedForward()</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="feedForward(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>feedForward</h4>
<pre>public&nbsp;java.util.List&lt;org.jblas.DoubleMatrix&gt;&nbsp;feedForward(org.jblas.DoubleMatrix&nbsp;input)</pre>
<div class="block">Compute activations from input to output of the output layer</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the list of activations for each layer</dd></dl>
</li>
</ul>
<a name="clone()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>clone</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;clone()</pre>
<dl>
<dt><strong>Overrides:</strong></dt>
<dd><code>clone</code>&nbsp;in class&nbsp;<code>java.lang.Object</code></dd>
</dl>
</li>
</ul>
<a name="backProp(double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backProp</h4>
<pre>public&nbsp;void&nbsp;backProp(double&nbsp;lr,
            int&nbsp;epochs)</pre>
<div class="block">Backpropagation of errors for weights</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lr</code> - the learning rate to use</dd><dd><code>epochs</code> - the number of epochs to iterate (this is already called in finetune)</dd></dl>
</li>
</ul>
<a name="backPropStep(org.deeplearning4j.nn.BaseMultiLayerNetwork, double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>backPropStep</h4>
<pre>protected&nbsp;void&nbsp;backPropStep(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;revert,
                double&nbsp;lr,
                int&nbsp;epoch)</pre>
<div class="block">Do a back prop iteration.
 This involves computing the activations, tracking the last layers weights
 to revert to in case of convergence, the learning rate being used to train
 and the current epoch</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>lastEntropy</code> - the last error to be had on the previous epoch</dd><dd><code>revert</code> - the best network so far</dd><dd><code>lr</code> - the learning rate to use for training</dd><dd><code>epoch</code> - the epoch to use</dd></dl>
</li>
</ul>
<a name="finetune(org.jblas.DoubleMatrix, double, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>finetune</h4>
<pre>public&nbsp;void&nbsp;finetune(org.jblas.DoubleMatrix&nbsp;labels,
            double&nbsp;lr,
            int&nbsp;epochs)</pre>
<div class="block">Run SGD based on the given labels</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>labels</code> - the labels to use</dd><dd><code>lr</code> - the learning rate during training</dd><dd><code>epochs</code> - the number of times to iterate</dd></dl>
</li>
</ul>
<a name="predict(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>predict</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;predict(org.jblas.DoubleMatrix&nbsp;x)</pre>
<div class="block">Label the probabilities of the input</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to label</dd>
<dt><span class="strong">Returns:</span></dt><dd>a vector of probabilities
 given each label.

 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="reconstruct(org.jblas.DoubleMatrix, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstruct</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;reconstruct(org.jblas.DoubleMatrix&nbsp;x,
                                 int&nbsp;layerNum)</pre>
<div class="block">Reconstructs the input.
 This is equivalent functionality to a
 deep autoencoder.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to reconstruct</dd><dd><code>layerNum</code> - the layer to output for encoding</dd>
<dt><span class="strong">Returns:</span></dt><dd>a reconstructed matrix
 relative to the size of the last hidden layer.
 This is great for data compression and visualizing
 high dimensional data (or just doing dimensionality reduction).

 This is typically of the form:
 [0.5, 0.5] or some other probability distribution summing to one</dd></dl>
</li>
</ul>
<a name="reconstruct(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>reconstruct</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;reconstruct(org.jblas.DoubleMatrix&nbsp;x)</pre>
<div class="block">Reconstruct from the final layer</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>x</code> - the input to reconstruct</dd>
<dt><span class="strong">Returns:</span></dt><dd>the reconstructed input</dd></dl>
</li>
</ul>
<a name="write(java.io.OutputStream)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>write</h4>
<pre>public&nbsp;void&nbsp;write(java.io.OutputStream&nbsp;os)</pre>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../org/deeplearning4j/nn/Persistable.html#write(java.io.OutputStream)">write</a></code>&nbsp;in interface&nbsp;<code><a href="../../../org/deeplearning4j/nn/Persistable.html" title="interface in org.deeplearning4j.nn">Persistable</a></code></dd>
</dl>
</li>
</ul>
<a name="load(java.io.InputStream)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>load</h4>
<pre>public&nbsp;void&nbsp;load(java.io.InputStream&nbsp;is)</pre>
<div class="block">Load (using <code>ObjectInputStream</code></div>
<dl>
<dt><strong>Specified by:</strong></dt>
<dd><code><a href="../../../org/deeplearning4j/nn/Persistable.html#load(java.io.InputStream)">load</a></code>&nbsp;in interface&nbsp;<code><a href="../../../org/deeplearning4j/nn/Persistable.html" title="interface in org.deeplearning4j.nn">Persistable</a></code></dd>
<dt><span class="strong">Parameters:</span></dt><dd><code>is</code> - the input stream to load from (usually a file)</dd></dl>
</li>
</ul>
<a name="loadFromFile(java.io.InputStream)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>loadFromFile</h4>
<pre>public static&nbsp;<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;loadFromFile(java.io.InputStream&nbsp;is)</pre>
<div class="block">Load (using <code>ObjectInputStream</code></div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>is</code> - the input stream to load from (usually a file)</dd></dl>
</li>
</ul>
<a name="update(org.deeplearning4j.nn.BaseMultiLayerNetwork)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>update</h4>
<pre>protected&nbsp;void&nbsp;update(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</pre>
<div class="block">Assigns the parameters of this model to the ones specified by this
 network. This is used in loading from input streams, factory methods, etc</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to get parameters from</dd></dl>
</li>
</ul>
<a name="negativeLogLikelihood()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>negativeLogLikelihood</h4>
<pre>public&nbsp;double&nbsp;negativeLogLikelihood()</pre>
<div class="block">Negative log likelihood of the model</div>
<dl><dt><span class="strong">Returns:</span></dt><dd>the negative log likelihood of the model</dd></dl>
</li>
</ul>
<a name="trainNetwork(org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, java.lang.Object[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>trainNetwork</h4>
<pre>public abstract&nbsp;void&nbsp;trainNetwork(org.jblas.DoubleMatrix&nbsp;input,
                org.jblas.DoubleMatrix&nbsp;labels,
                java.lang.Object[]&nbsp;otherParams)</pre>
<div class="block">Train the network running some unsupervised
 pretraining followed by SGD/finetune</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to train on</dd><dd><code>labels</code> - the labels for the training examples(a matrix of the following format:
 [0,1,0] where 0 represents the labels its not and 1 represents labels for the positive outcomes</dd><dd><code>otherParams</code> - the other parameters for child classes (algorithm specific parameters such as corruption level for SDA)</dd></dl>
</li>
</ul>
<a name="pretrain(org.jblas.DoubleMatrix, java.lang.Object[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>pretrain</h4>
<pre>public abstract&nbsp;void&nbsp;pretrain(org.jblas.DoubleMatrix&nbsp;input,
            java.lang.Object[]&nbsp;otherParams)</pre>
<div class="block">Pretrain the network with the given parameters</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to train ons</dd><dd><code>otherParams</code> - the other parameters for child classes (algorithm specific parameters such as corruption level for SDA)</dd></dl>
</li>
</ul>
<a name="applyTransforms()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>applyTransforms</h4>
<pre>protected&nbsp;void&nbsp;applyTransforms()</pre>
</li>
</ul>
<a name="createLayer(org.jblas.DoubleMatrix, int, int, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, org.jblas.DoubleMatrix, org.apache.commons.math3.random.RandomGenerator, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createLayer</h4>
<pre>public abstract&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>&nbsp;createLayer(org.jblas.DoubleMatrix&nbsp;input,
                        int&nbsp;nVisible,
                        int&nbsp;nHidden,
                        org.jblas.DoubleMatrix&nbsp;W,
                        org.jblas.DoubleMatrix&nbsp;hbias,
                        org.jblas.DoubleMatrix&nbsp;vBias,
                        org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
                        int&nbsp;index)</pre>
<div class="block">Creates a layer depending on the index.
 The main reason this matters is for continuous variations such as the <code>CDBN</code>
 where the first layer needs to be an <code>CRBM</code> for continuous inputs.

 Please be sure to call super.initializeNetwork

 to handle the passing of baseline parameters such as fanin
 and rendering.</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - the input to the layer</dd><dd><code>nVisible</code> - the number of visible inputs</dd><dd><code>nHidden</code> - the number of hidden units</dd><dd><code>W</code> - the weight vector</dd><dd><code>hbias</code> - the hidden bias</dd><dd><code>vBias</code> - the visible bias</dd><dd><code>rng</code> - the rng to use (THiS IS IMPORTANT; YOU DO NOT WANT TO HAVE A MIS REFERENCED RNG OTHERWISE NUMBERS WILL BE MEANINGLESS)</dd><dd><code>index</code> - the index of the layer</dd>
<dt><span class="strong">Returns:</span></dt><dd>a neural network layer such as <code>RBM</code></dd></dl>
</li>
</ul>
<a name="createNetworkLayers(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createNetworkLayers</h4>
<pre>public abstract&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]&nbsp;createNetworkLayers(int&nbsp;numLayers)</pre>
</li>
</ul>
<a name="createHiddenLayer(int, int, int, org.deeplearning4j.nn.activation.ActivationFunction, org.apache.commons.math3.random.RandomGenerator, org.jblas.DoubleMatrix, org.apache.commons.math3.distribution.RealDistribution)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>createHiddenLayer</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a>&nbsp;createHiddenLayer(int&nbsp;index,
                            int&nbsp;nIn,
                            int&nbsp;nOut,
                            <a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a>&nbsp;activation,
                            org.apache.commons.math3.random.RandomGenerator&nbsp;rng,
                            org.jblas.DoubleMatrix&nbsp;layerInput,
                            org.apache.commons.math3.distribution.RealDistribution&nbsp;dist)</pre>
<div class="block">Creates a hidden layer with the given parameters.
 The default implementation is a binomial sampling
 hidden layer, but this can be overriden
 for other kinds of hidden units</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>nIn</code> - the number of inputs</dd><dd><code>nOut</code> - the number of outputs</dd><dd><code>activation</code> - the activation function for the layer</dd><dd><code>rng</code> - the rng to use for sampling</dd><dd><code>layerInput</code> - the layer starting input</dd><dd><code>dist</code> - the probability distribution to use
 for generating weights</dd>
<dt><span class="strong">Returns:</span></dt><dd>a hidden layer with the given paremters</dd></dl>
</li>
</ul>
<a name="merge(org.deeplearning4j.nn.BaseMultiLayerNetwork, int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>merge</h4>
<pre>public&nbsp;void&nbsp;merge(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network,
         int&nbsp;batchSize)</pre>
<div class="block">Merges this network with the other one.
 This is a weight averaging with the update of:
 a += b - a / n
 where a is a matrix on the network
 b is the incoming matrix and n
 is the batch size.
 This update is performed across the network layers
 as well as hidden layers and logistic layers</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to merge with</dd><dd><code>batchSize</code> - the batch size (number of training examples)
 to average by</dd></dl>
</li>
</ul>
<a name="encode(org.deeplearning4j.nn.BaseMultiLayerNetwork)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>encode</h4>
<pre>public&nbsp;void&nbsp;encode(<a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.html" title="class in org.deeplearning4j.nn">BaseMultiLayerNetwork</a>&nbsp;network)</pre>
<div class="block">Transposes this network to turn it in to
 ad encoder for the given auto encoder networkk</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>network</code> - the network to decode</dd></dl>
</li>
</ul>
<a name="getLabels()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLabels</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;getLabels()</pre>
</li>
</ul>
<a name="getLogLayer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLogLayer</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/LogisticRegression.html" title="class in org.deeplearning4j.nn">LogisticRegression</a>&nbsp;getLogLayer()</pre>
</li>
</ul>
<a name="setInput(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setInput</h4>
<pre>public&nbsp;void&nbsp;setInput(org.jblas.DoubleMatrix&nbsp;input)</pre>
<div class="block">Note that if input isn't null
 and the layers are null, this is a way
 of initializing the neural network</div>
<dl><dt><span class="strong">Parameters:</span></dt><dd><code>input</code> - </dd></dl>
</li>
</ul>
<a name="isShouldBackProp()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isShouldBackProp</h4>
<pre>public&nbsp;boolean&nbsp;isShouldBackProp()</pre>
</li>
</ul>
<a name="getOptimizationAlgorithm()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizationAlgorithm</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a>&nbsp;getOptimizationAlgorithm()</pre>
</li>
</ul>
<a name="setOptimizationAlgorithm(org.deeplearning4j.nn.NeuralNetwork.OptimizationAlgorithm)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setOptimizationAlgorithm</h4>
<pre>public&nbsp;void&nbsp;setOptimizationAlgorithm(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.OptimizationAlgorithm.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.OptimizationAlgorithm</a>&nbsp;optimizationAlgorithm)</pre>
</li>
</ul>
<a name="getLossFunction()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLossFunction</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a>&nbsp;getLossFunction()</pre>
</li>
</ul>
<a name="setLossFunction(org.deeplearning4j.nn.NeuralNetwork.LossFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLossFunction</h4>
<pre>public&nbsp;void&nbsp;setLossFunction(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.LossFunction.html" title="enum in org.deeplearning4j.nn">NeuralNetwork.LossFunction</a>&nbsp;lossFunction)</pre>
</li>
</ul>
<a name="getInput()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getInput</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;getInput()</pre>
</li>
</ul>
<a name="getSigmoidLayers()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSigmoidLayers</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a>[]&nbsp;getSigmoidLayers()</pre>
</li>
</ul>
<a name="getLayers()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLayers</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]&nbsp;getLayers()</pre>
</li>
</ul>
<a name="isForceNumEpochs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isForceNumEpochs</h4>
<pre>public&nbsp;boolean&nbsp;isForceNumEpochs()</pre>
</li>
</ul>
<a name="getColumnSums()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getColumnSums</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;getColumnSums()</pre>
</li>
</ul>
<a name="setColumnSums(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setColumnSums</h4>
<pre>public&nbsp;void&nbsp;setColumnSums(org.jblas.DoubleMatrix&nbsp;columnSums)</pre>
</li>
</ul>
<a name="getHiddenLayerSizes()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHiddenLayerSizes</h4>
<pre>public&nbsp;int[]&nbsp;getHiddenLayerSizes()</pre>
</li>
</ul>
<a name="setHiddenLayerSizes(int[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setHiddenLayerSizes</h4>
<pre>public&nbsp;void&nbsp;setHiddenLayerSizes(int[]&nbsp;hiddenLayerSizes)</pre>
</li>
</ul>
<a name="getRng()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getRng</h4>
<pre>public&nbsp;org.apache.commons.math3.random.RandomGenerator&nbsp;getRng()</pre>
</li>
</ul>
<a name="setRng(org.apache.commons.math3.random.RandomGenerator)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setRng</h4>
<pre>public&nbsp;void&nbsp;setRng(org.apache.commons.math3.random.RandomGenerator&nbsp;rng)</pre>
</li>
</ul>
<a name="getDist()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDist</h4>
<pre>public&nbsp;org.apache.commons.math3.distribution.RealDistribution&nbsp;getDist()</pre>
</li>
</ul>
<a name="setDist(org.apache.commons.math3.distribution.RealDistribution)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setDist</h4>
<pre>public&nbsp;void&nbsp;setDist(org.apache.commons.math3.distribution.RealDistribution&nbsp;dist)</pre>
</li>
</ul>
<a name="getOptimizer()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getOptimizer</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/optimize/MultiLayerNetworkOptimizer.html" title="class in org.deeplearning4j.optimize">MultiLayerNetworkOptimizer</a>&nbsp;getOptimizer()</pre>
</li>
</ul>
<a name="setOptimizer(org.deeplearning4j.optimize.MultiLayerNetworkOptimizer)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setOptimizer</h4>
<pre>public&nbsp;void&nbsp;setOptimizer(<a href="../../../org/deeplearning4j/optimize/MultiLayerNetworkOptimizer.html" title="class in org.deeplearning4j.optimize">MultiLayerNetworkOptimizer</a>&nbsp;optimizer)</pre>
</li>
</ul>
<a name="getActivation()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getActivation</h4>
<pre>public&nbsp;<a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a>&nbsp;getActivation()</pre>
</li>
</ul>
<a name="setActivation(org.deeplearning4j.nn.activation.ActivationFunction)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setActivation</h4>
<pre>public&nbsp;void&nbsp;setActivation(<a href="../../../org/deeplearning4j/nn/activation/ActivationFunction.html" title="interface in org.deeplearning4j.nn.activation">ActivationFunction</a>&nbsp;activation)</pre>
</li>
</ul>
<a name="isToDecode()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isToDecode</h4>
<pre>public&nbsp;boolean&nbsp;isToDecode()</pre>
</li>
</ul>
<a name="setToDecode(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setToDecode</h4>
<pre>public&nbsp;void&nbsp;setToDecode(boolean&nbsp;toDecode)</pre>
</li>
</ul>
<a name="isShouldInit()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isShouldInit</h4>
<pre>public&nbsp;boolean&nbsp;isShouldInit()</pre>
</li>
</ul>
<a name="setShouldInit(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setShouldInit</h4>
<pre>public&nbsp;void&nbsp;setShouldInit(boolean&nbsp;shouldInit)</pre>
</li>
</ul>
<a name="getFanIn()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getFanIn</h4>
<pre>public&nbsp;double&nbsp;getFanIn()</pre>
</li>
</ul>
<a name="setFanIn(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setFanIn</h4>
<pre>public&nbsp;void&nbsp;setFanIn(double&nbsp;fanIn)</pre>
</li>
</ul>
<a name="getRenderWeightsEveryNEpochs()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getRenderWeightsEveryNEpochs</h4>
<pre>public&nbsp;int&nbsp;getRenderWeightsEveryNEpochs()</pre>
</li>
</ul>
<a name="setRenderWeightsEveryNEpochs(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setRenderWeightsEveryNEpochs</h4>
<pre>public&nbsp;void&nbsp;setRenderWeightsEveryNEpochs(int&nbsp;renderWeightsEveryNEpochs)</pre>
</li>
</ul>
<a name="getWeightTransforms()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getWeightTransforms</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;&nbsp;getWeightTransforms()</pre>
</li>
</ul>
<a name="setWeightTransforms(java.util.Map)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setWeightTransforms</h4>
<pre>public&nbsp;void&nbsp;setWeightTransforms(java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;&nbsp;weightTransforms)</pre>
</li>
</ul>
<a name="getSparsity()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getSparsity</h4>
<pre>public&nbsp;double&nbsp;getSparsity()</pre>
</li>
</ul>
<a name="setSparsity(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setSparsity</h4>
<pre>public&nbsp;void&nbsp;setSparsity(double&nbsp;sparsity)</pre>
</li>
</ul>
<a name="getLearningRateUpdate()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getLearningRateUpdate</h4>
<pre>public&nbsp;double&nbsp;getLearningRateUpdate()</pre>
</li>
</ul>
<a name="setLearningRateUpdate(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLearningRateUpdate</h4>
<pre>public&nbsp;void&nbsp;setLearningRateUpdate(double&nbsp;learningRateUpdate)</pre>
</li>
</ul>
<a name="getErrorTolerance()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getErrorTolerance</h4>
<pre>public&nbsp;double&nbsp;getErrorTolerance()</pre>
</li>
</ul>
<a name="setErrorTolerance(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setErrorTolerance</h4>
<pre>public&nbsp;void&nbsp;setErrorTolerance(double&nbsp;errorTolerance)</pre>
</li>
</ul>
<a name="setLabels(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLabels</h4>
<pre>public&nbsp;void&nbsp;setLabels(org.jblas.DoubleMatrix&nbsp;labels)</pre>
</li>
</ul>
<a name="setForceNumEpochs(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setForceNumEpochs</h4>
<pre>public&nbsp;void&nbsp;setForceNumEpochs(boolean&nbsp;forceNumEpochs)</pre>
</li>
</ul>
<a name="getColumnMeans()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getColumnMeans</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;getColumnMeans()</pre>
</li>
</ul>
<a name="setColumnMeans(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setColumnMeans</h4>
<pre>public&nbsp;void&nbsp;setColumnMeans(org.jblas.DoubleMatrix&nbsp;columnMeans)</pre>
</li>
</ul>
<a name="getColumnStds()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getColumnStds</h4>
<pre>public&nbsp;org.jblas.DoubleMatrix&nbsp;getColumnStds()</pre>
</li>
</ul>
<a name="setColumnStds(org.jblas.DoubleMatrix)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setColumnStds</h4>
<pre>public&nbsp;void&nbsp;setColumnStds(org.jblas.DoubleMatrix&nbsp;columnStds)</pre>
</li>
</ul>
<a name="isUseAdaGrad()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isUseAdaGrad</h4>
<pre>public&nbsp;boolean&nbsp;isUseAdaGrad()</pre>
</li>
</ul>
<a name="setUseAdaGrad(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUseAdaGrad</h4>
<pre>public&nbsp;void&nbsp;setUseAdaGrad(boolean&nbsp;useAdaGrad)</pre>
</li>
</ul>
<a name="isNormalizeByInputRows()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isNormalizeByInputRows</h4>
<pre>public&nbsp;boolean&nbsp;isNormalizeByInputRows()</pre>
</li>
</ul>
<a name="setNormalizeByInputRows(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setNormalizeByInputRows</h4>
<pre>public&nbsp;void&nbsp;setNormalizeByInputRows(boolean&nbsp;normalizeByInputRows)</pre>
</li>
</ul>
<a name="isUseHiddenActivationsForwardProp()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isUseHiddenActivationsForwardProp</h4>
<pre>public&nbsp;boolean&nbsp;isUseHiddenActivationsForwardProp()</pre>
</li>
</ul>
<a name="setUseHiddenActivationsForwardProp(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUseHiddenActivationsForwardProp</h4>
<pre>public&nbsp;void&nbsp;setUseHiddenActivationsForwardProp(boolean&nbsp;useHiddenActivationsForwardProp)</pre>
</li>
</ul>
<a name="getDropOut()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getDropOut</h4>
<pre>public&nbsp;double&nbsp;getDropOut()</pre>
</li>
</ul>
<a name="setDropOut(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setDropOut</h4>
<pre>public&nbsp;void&nbsp;setDropOut(double&nbsp;dropOut)</pre>
</li>
</ul>
<a name="getHiddenBiasTransforms()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getHiddenBiasTransforms</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;&nbsp;getHiddenBiasTransforms()</pre>
</li>
</ul>
<a name="getVisibleBiasTransforms()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getVisibleBiasTransforms</h4>
<pre>public&nbsp;java.util.Map&lt;java.lang.Integer,<a href="../../../org/deeplearning4j/transformation/MatrixTransform.html" title="interface in org.deeplearning4j.transformation">MatrixTransform</a>&gt;&nbsp;getVisibleBiasTransforms()</pre>
</li>
</ul>
<a name="getnIns()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnIns</h4>
<pre>public&nbsp;int&nbsp;getnIns()</pre>
</li>
</ul>
<a name="setnIns(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setnIns</h4>
<pre>public&nbsp;void&nbsp;setnIns(int&nbsp;nIns)</pre>
</li>
</ul>
<a name="getnOuts()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnOuts</h4>
<pre>public&nbsp;int&nbsp;getnOuts()</pre>
</li>
</ul>
<a name="setnOuts(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setnOuts</h4>
<pre>public&nbsp;void&nbsp;setnOuts(int&nbsp;nOuts)</pre>
</li>
</ul>
<a name="getnLayers()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getnLayers</h4>
<pre>public&nbsp;int&nbsp;getnLayers()</pre>
</li>
</ul>
<a name="setnLayers(int)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setnLayers</h4>
<pre>public&nbsp;void&nbsp;setnLayers(int&nbsp;nLayers)</pre>
</li>
</ul>
<a name="getMomentum()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getMomentum</h4>
<pre>public&nbsp;double&nbsp;getMomentum()</pre>
</li>
</ul>
<a name="setMomentum(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setMomentum</h4>
<pre>public&nbsp;void&nbsp;setMomentum(double&nbsp;momentum)</pre>
</li>
</ul>
<a name="getL2()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>getL2</h4>
<pre>public&nbsp;double&nbsp;getL2()</pre>
</li>
</ul>
<a name="setL2(double)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setL2</h4>
<pre>public&nbsp;void&nbsp;setL2(double&nbsp;l2)</pre>
</li>
</ul>
<a name="isUseRegularization()">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>isUseRegularization</h4>
<pre>public&nbsp;boolean&nbsp;isUseRegularization()</pre>
</li>
</ul>
<a name="setUseRegularization(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setUseRegularization</h4>
<pre>public&nbsp;void&nbsp;setUseRegularization(boolean&nbsp;useRegularization)</pre>
</li>
</ul>
<a name="setSigmoidLayers(org.deeplearning4j.nn.HiddenLayer[])">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setSigmoidLayers</h4>
<pre>public&nbsp;void&nbsp;setSigmoidLayers(<a href="../../../org/deeplearning4j/nn/HiddenLayer.html" title="class in org.deeplearning4j.nn">HiddenLayer</a>[]&nbsp;sigmoidLayers)</pre>
</li>
</ul>
<a name="setLogLayer(org.deeplearning4j.nn.LogisticRegression)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setLogLayer</h4>
<pre>public&nbsp;void&nbsp;setLogLayer(<a href="../../../org/deeplearning4j/nn/LogisticRegression.html" title="class in org.deeplearning4j.nn">LogisticRegression</a>&nbsp;logLayer)</pre>
</li>
</ul>
<a name="setShouldBackProp(boolean)">
<!--   -->
</a>
<ul class="blockList">
<li class="blockList">
<h4>setShouldBackProp</h4>
<pre>public&nbsp;void&nbsp;setShouldBackProp(boolean&nbsp;shouldBackProp)</pre>
</li>
</ul>
<a name="setLayers(org.deeplearning4j.nn.NeuralNetwork[])">
<!--   -->
</a>
<ul class="blockListLast">
<li class="blockList">
<h4>setLayers</h4>
<pre>public&nbsp;void&nbsp;setLayers(<a href="../../../org/deeplearning4j/nn/NeuralNetwork.html" title="interface in org.deeplearning4j.nn">NeuralNetwork</a>[]&nbsp;layers)</pre>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
</div>
<!-- ========= END OF CLASS DATA ========= -->
<!-- ======= START OF BOTTOM NAVBAR ====== -->
<div class="bottomNav"><a name="navbar_bottom">
<!--   -->
</a><a href="#skip-navbar_bottom" title="Skip navigation links"></a><a name="navbar_bottom_firstrow">
<!--   -->
</a>
<ul class="navList" title="Navigation">
<li><a href="../../../overview-summary.html">Overview</a></li>
<li><a href="package-summary.html">Package</a></li>
<li class="navBarCell1Rev">Class</li>
<li><a href="package-tree.html">Tree</a></li>
<li><a href="../../../deprecated-list.html">Deprecated</a></li>
<li><a href="../../../index-files/index-1.html">Index</a></li>
<li><a href="../../../help-doc.html">Help</a></li>
</ul>
</div>
<div class="subNav">
<ul class="navList">
<li>Prev Class</li>
<li><a href="../../../org/deeplearning4j/nn/BaseMultiLayerNetwork.Builder.html" title="class in org.deeplearning4j.nn"><span class="strong">Next Class</span></a></li>
</ul>
<ul class="navList">
<li><a href="../../../index.html?org/deeplearning4j/nn/BaseMultiLayerNetwork.html" target="_top">Frames</a></li>
<li><a href="BaseMultiLayerNetwork.html" target="_top">No Frames</a></li>
</ul>
<ul class="navList" id="allclasses_navbar_bottom">
<li><a href="../../../allclasses-noframe.html">All Classes</a></li>
</ul>
<div>
<script type="text/javascript"><!--
  allClassesLink = document.getElementById("allclasses_navbar_bottom");
  if(window==top) {
    allClassesLink.style.display = "block";
  }
  else {
    allClassesLink.style.display = "none";
  }
  //-->
</script>
</div>
<div>
<ul class="subNavList">
<li>Summary:&nbsp;</li>
<li><a href="#nested_class_summary">Nested</a>&nbsp;|&nbsp;</li>
<li><a href="#field_summary">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_summary">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_summary">Method</a></li>
</ul>
<ul class="subNavList">
<li>Detail:&nbsp;</li>
<li><a href="#field_detail">Field</a>&nbsp;|&nbsp;</li>
<li><a href="#constructor_detail">Constr</a>&nbsp;|&nbsp;</li>
<li><a href="#method_detail">Method</a></li>
</ul>
</div>
<a name="skip-navbar_bottom">
<!--   -->
</a></div>
<!-- ======== END OF BOTTOM NAVBAR ======= -->
</body>
</html>
